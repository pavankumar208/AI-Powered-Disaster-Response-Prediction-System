# -*- coding: utf-8 -*-
"""Untitled25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PxFOjzSJlHVdcBgKkwyJ9HA-3rLwlH7r
"""

# AI-Powered Disaster Response & Prediction System
# Core modules: Multi-modal Data Ingestion, Prediction using Transformer, RL Agent for Response Planning

import torch
import torch.nn as nn
from transformers import BertModel, BertTokenizer, ViTModel
import numpy as np
import gym

# --- CONFIG ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- MODULE 1: Multi-modal Data Preprocessing ---
def preprocess_text(text):
    tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    return inputs

def preprocess_image_dummy():
    # Instead of loading an image, we create a dummy tensor that mimics ViT input
    # ViT expects shape [batch_size, 3, 224, 224]
    return torch.randn(1, 3, 224, 224)

# --- MODULE 2: Multi-modal Transformer Model ---
class DisasterPredictor(nn.Module):
    def __init__(self):
        super(DisasterPredictor, self).__init__()
        self.text_model = BertModel.from_pretrained("bert-base-uncased")
        self.image_model = ViTModel.from_pretrained("google/vit-base-patch16-224")
        self.fc = nn.Linear(self.text_model.config.hidden_size + self.image_model.config.hidden_size, 2)

    def forward(self, text_input, image_input):
        text_output = self.text_model(**text_input).pooler_output
        image_output = self.image_model(pixel_values=image_input).pooler_output
        combined = torch.cat((text_output, image_output), dim=1)
        return self.fc(combined)

# --- MODULE 3: Reinforcement Learning Agent for Action Planning ---
class DisasterEnv(gym.Env):
    def __init__(self):
        super(DisasterEnv, self).__init__()
        self.action_space = gym.spaces.Discrete(4)  # 0: Alert, 1: Deploy, 2: Evacuate, 3: Wait
        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(10,), dtype=np.float32)

    def reset(self):
        self.state = np.random.rand(10)
        return self.state

    def step(self, action):
        reward = np.random.randn()  # Mock reward
        done = np.random.rand() > 0.95
        self.state = np.random.rand(10)
        return self.state, reward, done, {}

class RLAgent(nn.Module):
    def __init__(self, input_size, action_size):
        super(RLAgent, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, action_size)
        )

    def forward(self, x):
        return self.fc(x)

# --- INFERENCE EXAMPLE ---
if __name__ == "__main__":
    # Sample input text
    text = "Heavy rainfall in Chennai with risk of urban flooding."

    # Preprocess text and dummy image
    text_input = preprocess_text(text)
    image_input = preprocess_image_dummy()

    # Initialize and run disaster prediction model
    model = DisasterPredictor().to(DEVICE)
    model.eval()
    with torch.no_grad():
        output = model({k: v.to(DEVICE) for k, v in text_input.items()}, image_input.to(DEVICE))
        probs = torch.softmax(output, dim=1)
        print("Disaster prediction (probabilities):", probs.cpu().numpy())

    # Initialize and run RL agent in mock environment
    env = DisasterEnv()
    agent = RLAgent(input_size=10, action_size=4).to(DEVICE)
    state = torch.FloatTensor(env.reset()).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        action = torch.argmax(agent(state)).item()
        actions_map = {0: "Alert", 1: "Deploy", 2: "Evacuate", 3: "Wait"}
        print("Recommended Action:", action, "-", actions_map[action])